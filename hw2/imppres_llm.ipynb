{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c468709d",
   "metadata": {},
   "source": [
    "# ImpPres with LLM\n",
    "\n",
    "You have to implement in this notebook a better ImpPres classifier using an LLM.\n",
    "This classifier must be implemented using DSPy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cec0d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the DSPy environment with the language model - for grok the parameters must be:\n",
    "# env variable should be in os.environ['XAI_API_KEY']\n",
    "# \"xai/grok-3-mini\"\n",
    "\n",
    "import os\n",
    "import dspy\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"grok_key.ini\") \n",
    "\n",
    "lm = dspy.LM('xai/grok-3-mini', api_key=os.environ['XAI_API_KEY'])\n",
    "# for ollama \n",
    "# lm = dspy.LM('ollama_chat/devstral', api_base='http://localhost:11434', api_key='')\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b60da44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, List\n",
    "\n",
    "## Implement the DSPy classifier program.\n",
    "class ParadigmClassifier(dspy.Signature):\n",
    "    pairs: str = dspy.InputField(desc=\"All premise-hypothesis pairs, numbered and separated by |\")\n",
    "    predictions: List[Literal['entailment', 'neutral', 'contradiction']] = dspy.OutputField(desc=\"List of predictions for each pair\")\n",
    "\n",
    "classifier = dspy.Predict(ParadigmClassifier)\n",
    "\n",
    "def classify(paradigm_pairs):\n",
    "    pairs = []\n",
    "    for i, pair in enumerate(paradigm_pairs):\n",
    "        s = f\"{i + 1}. Premise: {pair['premise']}, Hypothesis: {pair['hypothesis']}\"\n",
    "        pairs.append(s)\n",
    "\n",
    "    pairs_str = \" | \".join(pairs)\n",
    "    results = classifier(pairs=pairs_str)\n",
    "\n",
    "    return results.predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ab422d",
   "metadata": {},
   "source": [
    "## Load ImpPres Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0438789b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset for section: presupposition_all_n_presupposition\n",
      "Loading dataset for section: presupposition_both_presupposition\n",
      "Loading dataset for section: presupposition_change_of_state\n",
      "Loading dataset for section: presupposition_cleft_existence\n",
      "Loading dataset for section: presupposition_cleft_uniqueness\n",
      "Loading dataset for section: presupposition_only_presupposition\n",
      "Loading dataset for section: presupposition_possessed_definites_existence\n",
      "Loading dataset for section: presupposition_possessed_definites_uniqueness\n",
      "Loading dataset for section: presupposition_question_presupposition\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "sections = ['presupposition_all_n_presupposition', \n",
    "            'presupposition_both_presupposition', \n",
    "            'presupposition_change_of_state', \n",
    "            'presupposition_cleft_existence', \n",
    "            'presupposition_cleft_uniqueness', \n",
    "            'presupposition_only_presupposition', \n",
    "            'presupposition_possessed_definites_existence', \n",
    "            'presupposition_possessed_definites_uniqueness', \n",
    "            'presupposition_question_presupposition']\n",
    "\n",
    "dataset = {}\n",
    "for section in sections:\n",
    "    print(f\"Loading dataset for section: {section}\")\n",
    "    dataset[section] = load_dataset(\"facebook/imppres\", section)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8e1258",
   "metadata": {},
   "source": [
    "## Evaluate Metrics\n",
    "\n",
    "Let's use the huggingface `evaluate` package to compute the performance of the baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e2e9027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "accuracy = load(\"accuracy\")\n",
    "precision = load(\"precision\")\n",
    "recall = load(\"recall\")\n",
    "f1 = load(\"f1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ab24e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "613fcaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "def evaluate_paradigm_section(dataset):\n",
    "    # dataset = dataset.select(range(380))\n",
    "    results = []\n",
    "    label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "    consistency_scores = []\n",
    "\n",
    "    # Make paradigm groups\n",
    "    paradigms = []\n",
    "    for i in range(0, len(dataset), 19):\n",
    "        if i + 19 <= len(dataset):\n",
    "            paradigm = []\n",
    "            for j in range(19):\n",
    "                example = dataset[i + j]\n",
    "                paradigm.append({\n",
    "                    'premise': example['premise'],\n",
    "                    'hypothesis': example['hypothesis'],\n",
    "                    'gold_label': label_names[example['gold_label']]\n",
    "                })\n",
    "            paradigms.append(paradigm)\n",
    "\n",
    "    for paradigm in tqdm(paradigms):\n",
    "        pairs = [{'premise': pair['premise'], 'hypothesis': pair['hypothesis']} for pair in paradigm]\n",
    "        predictions = classify(pairs)\n",
    "    \n",
    "        # Calculate consistency score - the proportion of the most common prediction\n",
    "        pred_counts = defaultdict(int)\n",
    "        for pred in predictions:\n",
    "            pred_counts[pred] += 1\n",
    "        consistency = max(pred_counts.values()) / len(predictions)\n",
    "        consistency_scores.append(consistency)\n",
    "\n",
    "        for (pred, gold) in zip(predictions, paradigm):\n",
    "            results.append({\n",
    "                'pred_label': pred,\n",
    "                'gold_label': gold['gold_label']\n",
    "            })  \n",
    "\n",
    "    consistency = sum(consistency_scores) / len(consistency_scores)\n",
    "\n",
    "    return results, consistency\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cfb5a489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on section: presupposition_all_n_presupposition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 709.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on section: presupposition_both_presupposition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [14:44<00:00,  8.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on section: presupposition_change_of_state\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [14:02<00:00,  8.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on section: presupposition_cleft_existence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [15:14<00:00,  9.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on section: presupposition_cleft_uniqueness\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [14:01<00:00,  8.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on section: presupposition_only_presupposition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [14:43<00:00,  8.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on section: presupposition_possessed_definites_existence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [14:11<00:00,  8.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on section: presupposition_possessed_definites_uniqueness\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [14:17<00:00,  8.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on section: presupposition_question_presupposition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [14:35<00:00,  8.75s/it]\n"
     ]
    }
   ],
   "source": [
    "for section in sections:\n",
    "    print(f\"Working on section: {section}\")\n",
    "    sec = section[15:]\n",
    "    data = dataset[section][sec]\n",
    "\n",
    "    evaluate_paradigm_section(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
