{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c468709d",
   "metadata": {},
   "source": [
    "# ImpPres LLM Baseline\n",
    "\n",
    "You have to implement in this notebook a baseline for ImpPres classification using an LLM.\n",
    "This baseline must be implemented using DSPy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cec0d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the DSPy environment with the language model - for grok the parameters must be:\n",
    "# env variable should be in os.environ['XAI_API_KEY']\n",
    "# \"xai/grok-3-mini\"\n",
    "import os\n",
    "import dspy\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"grok_key.ini\") \n",
    "lm = dspy.LM('xai/grok-3-mini', api_key=os.environ['XAI_API_KEY'])\n",
    "# for ollama \n",
    "# lm = dspy.LM('ollama_chat/devstral', api_base='http://localhost:11434', api_key='')\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d566d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "## Implement the DSPy program to classify pairs (premise, hypothesis) as entailment, contradiction, or neutral.\n",
    "\n",
    "class ImpPresClassifier(dspy.Signature):\n",
    "    premise: str = dspy.InputField()\n",
    "    hypothesis: str = dspy.InputField()\n",
    "    label: Literal['entailment', 'neutral', 'contradiction'] = dspy.OutputField()\n",
    "\n",
    "classifier = dspy.Predict(ImpPresClassifier)\n",
    "\n",
    "def classify(premise, hypothesis):\n",
    "    return classifier(premise=premise, hypothesis=hypothesis).label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbb15aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImpPresCoTClassifier(dspy.Signature):\n",
    "    premise: str = dspy.InputField()\n",
    "    hypothesis: str = dspy.InputField()\n",
    "    explanation: str = dspy.OutputField(desc=\"Explain the reasoning for the classification\")\n",
    "    label: Literal['entailment', 'neutral', 'contradiction'] = dspy.OutputField()\n",
    "\n",
    "cot_classifier = dspy.Predict(ImpPresCoTClassifier)\n",
    "\n",
    "def classify_cot(premise, hypothesis):\n",
    "    return cot_classifier(premise=premise, hypothesis=hypothesis).label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ab422d",
   "metadata": {},
   "source": [
    "## Load ImpPres dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0438789b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset for section: presupposition_all_n_presupposition\n",
      "Loading dataset for section: presupposition_both_presupposition\n",
      "Loading dataset for section: presupposition_change_of_state\n",
      "Loading dataset for section: presupposition_cleft_existence\n",
      "Loading dataset for section: presupposition_cleft_uniqueness\n",
      "Loading dataset for section: presupposition_only_presupposition\n",
      "Loading dataset for section: presupposition_possessed_definites_existence\n",
      "Loading dataset for section: presupposition_possessed_definites_uniqueness\n",
      "Loading dataset for section: presupposition_question_presupposition\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "sections = ['presupposition_all_n_presupposition', \n",
    "            'presupposition_both_presupposition', \n",
    "            'presupposition_change_of_state', \n",
    "            'presupposition_cleft_existence', \n",
    "            'presupposition_cleft_uniqueness', \n",
    "            'presupposition_only_presupposition', \n",
    "            'presupposition_possessed_definites_existence', \n",
    "            'presupposition_possessed_definites_uniqueness', \n",
    "            'presupposition_question_presupposition']\n",
    "\n",
    "dataset = {}\n",
    "for section in sections:\n",
    "    print(f\"Loading dataset for section: {section}\")\n",
    "    dataset[section] = load_dataset(\"facebook/imppres\", section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e59927ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'presupposition_all_n_presupposition': DatasetDict({\n",
       "     all_n_presupposition: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_both_presupposition': DatasetDict({\n",
       "     both_presupposition: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_change_of_state': DatasetDict({\n",
       "     change_of_state: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_cleft_existence': DatasetDict({\n",
       "     cleft_existence: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_cleft_uniqueness': DatasetDict({\n",
       "     cleft_uniqueness: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_only_presupposition': DatasetDict({\n",
       "     only_presupposition: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_possessed_definites_existence': DatasetDict({\n",
       "     possessed_definites_existence: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_possessed_definites_uniqueness': DatasetDict({\n",
       "     possessed_definites_uniqueness: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_question_presupposition': DatasetDict({\n",
       "     question_presupposition: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " })}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8e1258",
   "metadata": {},
   "source": [
    "## Evaluate Metrics\n",
    "\n",
    "Let's use the huggingface `evaluate` package to compute the performance of the baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd84405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "accuracy = load(\"accuracy\")\n",
    "precision = load(\"precision\")\n",
    "recall = load(\"recall\")\n",
    "f1 = load(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ab24e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52de9582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_on_section(dataset, use_cot):\n",
    "    results = []\n",
    "    label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "    for example in tqdm(dataset):\n",
    "        premise = example['premise']\n",
    "        hypothesis = example['hypothesis']\n",
    "        if use_cot:\n",
    "            prediction = classify_cot(premise, hypothesis)\n",
    "        else:\n",
    "            prediction = classify(premise, hypothesis)\n",
    "        results.append({\n",
    "            'pred_label': prediction,\n",
    "            'gold_label': label_names[example['gold_label']],\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4571f1b5",
   "metadata": {},
   "source": [
    "### Basic classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183de4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on section: presupposition_all_n_presupposition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 532.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on section: presupposition_both_presupposition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [02:42<00:00,  4.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on section: presupposition_change_of_state\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [02:30<00:00,  3.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on section: presupposition_cleft_existence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [02:35<00:00,  3.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on section: presupposition_cleft_uniqueness\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [02:38<00:00,  3.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on section: presupposition_only_presupposition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [02:41<00:00,  4.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on section: presupposition_possessed_definites_existence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [02:28<00:00,  3.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on section: presupposition_possessed_definites_uniqueness\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [02:48<00:00,  4.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on section: presupposition_question_presupposition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [02:34<00:00,  3.87s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a0f6d th {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_a0f6d_row0_col0, #T_a0f6d_row0_col1, #T_a0f6d_row0_col2, #T_a0f6d_row0_col3, #T_a0f6d_row0_col4, #T_a0f6d_row1_col0, #T_a0f6d_row1_col1, #T_a0f6d_row1_col2, #T_a0f6d_row1_col3, #T_a0f6d_row1_col4, #T_a0f6d_row2_col0, #T_a0f6d_row2_col1, #T_a0f6d_row2_col2, #T_a0f6d_row2_col3, #T_a0f6d_row2_col4, #T_a0f6d_row3_col0, #T_a0f6d_row3_col1, #T_a0f6d_row3_col2, #T_a0f6d_row3_col3, #T_a0f6d_row3_col4, #T_a0f6d_row4_col0, #T_a0f6d_row4_col1, #T_a0f6d_row4_col2, #T_a0f6d_row4_col3, #T_a0f6d_row4_col4, #T_a0f6d_row5_col0, #T_a0f6d_row5_col1, #T_a0f6d_row5_col2, #T_a0f6d_row5_col3, #T_a0f6d_row5_col4, #T_a0f6d_row6_col0, #T_a0f6d_row6_col1, #T_a0f6d_row6_col2, #T_a0f6d_row6_col3, #T_a0f6d_row6_col4, #T_a0f6d_row7_col0, #T_a0f6d_row7_col1, #T_a0f6d_row7_col2, #T_a0f6d_row7_col3, #T_a0f6d_row7_col4, #T_a0f6d_row8_col0, #T_a0f6d_row8_col1, #T_a0f6d_row8_col2, #T_a0f6d_row8_col3, #T_a0f6d_row8_col4, #T_a0f6d_row9_col0, #T_a0f6d_row9_col1, #T_a0f6d_row9_col2, #T_a0f6d_row9_col3, #T_a0f6d_row9_col4 {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a0f6d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a0f6d_level0_col0\" class=\"col_heading level0 col0\" >Section</th>\n",
       "      <th id=\"T_a0f6d_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_a0f6d_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
       "      <th id=\"T_a0f6d_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_a0f6d_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a0f6d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a0f6d_row0_col0\" class=\"data row0 col0\" >all_n_presupposition</td>\n",
       "      <td id=\"T_a0f6d_row0_col1\" class=\"data row0 col1\" >0.97</td>\n",
       "      <td id=\"T_a0f6d_row0_col2\" class=\"data row0 col2\" >0.98</td>\n",
       "      <td id=\"T_a0f6d_row0_col3\" class=\"data row0 col3\" >0.97</td>\n",
       "      <td id=\"T_a0f6d_row0_col4\" class=\"data row0 col4\" >0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0f6d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a0f6d_row1_col0\" class=\"data row1 col0\" >both_presupposition</td>\n",
       "      <td id=\"T_a0f6d_row1_col1\" class=\"data row1 col1\" >1.00</td>\n",
       "      <td id=\"T_a0f6d_row1_col2\" class=\"data row1 col2\" >1.00</td>\n",
       "      <td id=\"T_a0f6d_row1_col3\" class=\"data row1 col3\" >1.00</td>\n",
       "      <td id=\"T_a0f6d_row1_col4\" class=\"data row1 col4\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0f6d_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_a0f6d_row2_col0\" class=\"data row2 col0\" >change_of_state</td>\n",
       "      <td id=\"T_a0f6d_row2_col1\" class=\"data row2 col1\" >0.60</td>\n",
       "      <td id=\"T_a0f6d_row2_col2\" class=\"data row2 col2\" >0.69</td>\n",
       "      <td id=\"T_a0f6d_row2_col3\" class=\"data row2 col3\" >0.55</td>\n",
       "      <td id=\"T_a0f6d_row2_col4\" class=\"data row2 col4\" >0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0f6d_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_a0f6d_row3_col0\" class=\"data row3 col0\" >cleft_existence</td>\n",
       "      <td id=\"T_a0f6d_row3_col1\" class=\"data row3 col1\" >0.68</td>\n",
       "      <td id=\"T_a0f6d_row3_col2\" class=\"data row3 col2\" >0.85</td>\n",
       "      <td id=\"T_a0f6d_row3_col3\" class=\"data row3 col3\" >0.63</td>\n",
       "      <td id=\"T_a0f6d_row3_col4\" class=\"data row3 col4\" >0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0f6d_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_a0f6d_row4_col0\" class=\"data row4 col0\" >cleft_uniqueness</td>\n",
       "      <td id=\"T_a0f6d_row4_col1\" class=\"data row4 col1\" >0.45</td>\n",
       "      <td id=\"T_a0f6d_row4_col2\" class=\"data row4 col2\" >0.47</td>\n",
       "      <td id=\"T_a0f6d_row4_col3\" class=\"data row4 col3\" >0.38</td>\n",
       "      <td id=\"T_a0f6d_row4_col4\" class=\"data row4 col4\" >0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0f6d_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_a0f6d_row5_col0\" class=\"data row5 col0\" >only_presupposition</td>\n",
       "      <td id=\"T_a0f6d_row5_col1\" class=\"data row5 col1\" >0.75</td>\n",
       "      <td id=\"T_a0f6d_row5_col2\" class=\"data row5 col2\" >0.87</td>\n",
       "      <td id=\"T_a0f6d_row5_col3\" class=\"data row5 col3\" >0.72</td>\n",
       "      <td id=\"T_a0f6d_row5_col4\" class=\"data row5 col4\" >0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0f6d_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_a0f6d_row6_col0\" class=\"data row6 col0\" >possessed_definites_existence</td>\n",
       "      <td id=\"T_a0f6d_row6_col1\" class=\"data row6 col1\" >0.95</td>\n",
       "      <td id=\"T_a0f6d_row6_col2\" class=\"data row6 col2\" >0.96</td>\n",
       "      <td id=\"T_a0f6d_row6_col3\" class=\"data row6 col3\" >0.94</td>\n",
       "      <td id=\"T_a0f6d_row6_col4\" class=\"data row6 col4\" >0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0f6d_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_a0f6d_row7_col0\" class=\"data row7 col0\" >possessed_definites_uniqueness</td>\n",
       "      <td id=\"T_a0f6d_row7_col1\" class=\"data row7 col1\" >0.45</td>\n",
       "      <td id=\"T_a0f6d_row7_col2\" class=\"data row7 col2\" >0.47</td>\n",
       "      <td id=\"T_a0f6d_row7_col3\" class=\"data row7 col3\" >0.38</td>\n",
       "      <td id=\"T_a0f6d_row7_col4\" class=\"data row7 col4\" >0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0f6d_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_a0f6d_row8_col0\" class=\"data row8 col0\" >question_presupposition</td>\n",
       "      <td id=\"T_a0f6d_row8_col1\" class=\"data row8 col1\" >0.82</td>\n",
       "      <td id=\"T_a0f6d_row8_col2\" class=\"data row8 col2\" >0.90</td>\n",
       "      <td id=\"T_a0f6d_row8_col3\" class=\"data row8 col3\" >0.80</td>\n",
       "      <td id=\"T_a0f6d_row8_col4\" class=\"data row8 col4\" >0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0f6d_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_a0f6d_row9_col0\" class=\"data row9 col0\" >Overall</td>\n",
       "      <td id=\"T_a0f6d_row9_col1\" class=\"data row9 col1\" >0.74</td>\n",
       "      <td id=\"T_a0f6d_row9_col2\" class=\"data row9 col2\" >0.80</td>\n",
       "      <td id=\"T_a0f6d_row9_col3\" class=\"data row9 col3\" >0.71</td>\n",
       "      <td id=\"T_a0f6d_row9_col4\" class=\"data row9 col4\" >0.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14071e94410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "results_table = []\n",
    "\n",
    "for section in sections:\n",
    "    print(f\"Working on section: {section}\")\n",
    "    sec = section[15:]\n",
    "\n",
    "    data = dataset[section]\n",
    "    data = data[sec].select(range(40))\n",
    "\n",
    "    section_results = evaluate_on_section(data, False)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    predictions = [result['pred_label'] for result in section_results]\n",
    "    references = [result['gold_label'] for result in section_results]\n",
    "\n",
    "    label_to_int = {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2}\n",
    "    predictions_int = [label_to_int[pred] for pred in predictions]\n",
    "    references_int = [label_to_int[ref] for ref in references]\n",
    "\n",
    "    accuracy_score = accuracy.compute(predictions=predictions_int, references=references_int)['accuracy']\n",
    "    f1_score = f1.compute(predictions=predictions_int, references=references_int, average='macro')['f1']\n",
    "    precision_score = precision.compute(predictions=predictions_int, references=references_int, average='macro', zero_division=0)['precision']\n",
    "    recall_score = recall.compute(predictions=predictions_int, references=references_int, average='macro', zero_division=0)['recall']\n",
    "    \n",
    "    accuracies.append(accuracy_score)\n",
    "    precisions.append(precision_score)\n",
    "    recalls.append(recall_score)\n",
    "    f1s.append(f1_score)\n",
    "\n",
    "    # Append results to the table\n",
    "    results_table.append({\n",
    "        'Section': sec,\n",
    "        'Accuracy': f\"{accuracy_score:.2f}\",\n",
    "        'Precision': f\"{precision_score:.2f}\",\n",
    "        'Recall': f\"{recall_score:.2f}\",\n",
    "        'F1': f\"{f1_score:.2f}\",\n",
    "    })\n",
    "\n",
    "# Calculate overall metrics\n",
    "accuracy_all = sum(accuracies) / len(accuracies)\n",
    "precision_all = sum(precisions) / len(precisions)\n",
    "recall_all = sum(recalls) / len(recalls)\n",
    "f1_all = sum(f1s) / len(f1s)\n",
    "\n",
    "results_table.append({\n",
    "    'Section': 'Overall',\n",
    "    'Accuracy': f\"{accuracy_all:.2f}\",\n",
    "    'Precision': f\"{precision_all:.2f}\",\n",
    "    'Recall': f\"{recall_all:.2f}\",\n",
    "    'F1': f\"{f1_all:.2f}\",\n",
    "})\n",
    "\n",
    "# Display results as a table\n",
    "results_df = pd.DataFrame(results_table)\n",
    "styled_df = results_df.style.set_properties(**{'text-align': 'center'})\n",
    "styled_df = styled_df.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\n",
    "display(styled_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4820064b",
   "metadata": {},
   "source": [
    "### Chain of Thought Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0a239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "results_table = []\n",
    "\n",
    "for section in sections:\n",
    "    print(f\"Working on section: {section}\")\n",
    "    sec = section[15:]\n",
    "\n",
    "    data = dataset[section]\n",
    "    data = data[sec].select(range(10))\n",
    "\n",
    "    section_results = evaluate_on_section(data, True)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    predictions = [result['pred_label'] for result in section_results]\n",
    "    references = [result['gold_label'] for result in section_results]\n",
    "\n",
    "    label_to_int = {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2}\n",
    "    predictions_int = [label_to_int[pred] for pred in predictions]\n",
    "    references_int = [label_to_int[ref] for ref in references]\n",
    "\n",
    "    accuracy_score = accuracy.compute(predictions=predictions_int, references=references_int)['accuracy']\n",
    "    f1_score = f1.compute(predictions=predictions_int, references=references_int, average='macro')['f1']\n",
    "    precision_score = precision.compute(predictions=predictions_int, references=references_int, average='macro', zero_division=0)['precision']\n",
    "    recall_score = recall.compute(predictions=predictions_int, references=references_int, average='macro', zero_division=0)['recall']\n",
    "    \n",
    "    accuracies.append(accuracy_score)\n",
    "    precisions.append(precision_score)\n",
    "    recalls.append(recall_score)\n",
    "    f1s.append(f1_score)\n",
    "\n",
    "    # Append results to the table\n",
    "    results_table.append({\n",
    "        'Section': sec,\n",
    "        'Accuracy': f\"{accuracy_score:.2f}\",\n",
    "        'Precision': f\"{precision_score:.2f}\",\n",
    "        'Recall': f\"{recall_score:.2f}\",\n",
    "        'F1': f\"{f1_score:.2f}\",\n",
    "    })\n",
    "\n",
    "# Calculate overall metrics\n",
    "accuracy_all = sum(accuracies) / len(accuracies)\n",
    "precision_all = sum(precisions) / len(precisions)\n",
    "recall_all = sum(recalls) / len(recalls)\n",
    "f1_all = sum(f1s) / len(f1s)\n",
    "\n",
    "results_table.append({\n",
    "    'Section': 'Overall',\n",
    "    'Accuracy': f\"{accuracy_all:.2f}\",\n",
    "    'Precision': f\"{precision_all:.2f}\",\n",
    "    'Recall': f\"{recall_all:.2f}\",\n",
    "    'F1': f\"{f1_all:.2f}\",\n",
    "})\n",
    "\n",
    "# Display results as a table\n",
    "results_df = pd.DataFrame(results_table)\n",
    "styled_df = results_df.style.set_properties(**{'text-align': 'center'})\n",
    "styled_df = styled_df.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\n",
    "display(styled_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
