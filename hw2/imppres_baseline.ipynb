{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c468709d",
   "metadata": {},
   "source": [
    "# ImpPres Baseline\n",
    "\n",
    "This notebook illustrates how to use the DeBERTa-v3-base-mnli-fever-anli model to perform specialized inference on the ImpPres dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cec0d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cfe31ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "def evaluate(premise, hypothesis):\n",
    "    input = tokenizer(premise, hypothesis, truncation=True, return_tensors=\"pt\")\n",
    "    output = model(input[\"input_ids\"].to(device))\n",
    "    prediction = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
    "    prediction = {name: round(float(pred) * 100, 1) for pred, name in zip(prediction, label_names)}\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2954d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'entailment': 0.1, 'neutral': 99.8, 'contradiction': 0.0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\"The weather is nice today.\", \"It is sunny outside.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "923ea5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(pred_dict):\n",
    "    if pred_dict[\"entailment\"] > pred_dict[\"contradiction\"]  and pred_dict[\"entailment\"] > pred_dict[\"neutral\"]:\n",
    "        return \"entailment\"\n",
    "    elif pred_dict[\"contradiction\"] > pred_dict[\"entailment\"]  and pred_dict[\"contradiction\"] > pred_dict[\"neutral\"]:\n",
    "        return \"contradiction\"\n",
    "    else:\n",
    "        return \"neutral\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ab422d",
   "metadata": {},
   "source": [
    "## Load ImpPres Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0438789b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset for section: presupposition_all_n_presupposition\n",
      "Loading dataset for section: presupposition_both_presupposition\n",
      "Loading dataset for section: presupposition_change_of_state\n",
      "Loading dataset for section: presupposition_cleft_existence\n",
      "Loading dataset for section: presupposition_cleft_uniqueness\n",
      "Loading dataset for section: presupposition_only_presupposition\n",
      "Loading dataset for section: presupposition_possessed_definites_existence\n",
      "Loading dataset for section: presupposition_possessed_definites_uniqueness\n",
      "Loading dataset for section: presupposition_question_presupposition\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "sections = ['presupposition_all_n_presupposition', \n",
    "            'presupposition_both_presupposition', \n",
    "            'presupposition_change_of_state', \n",
    "            'presupposition_cleft_existence', \n",
    "            'presupposition_cleft_uniqueness', \n",
    "            'presupposition_only_presupposition', \n",
    "            'presupposition_possessed_definites_existence', \n",
    "            'presupposition_possessed_definites_uniqueness', \n",
    "            'presupposition_question_presupposition']\n",
    "\n",
    "dataset = {}\n",
    "for section in sections:\n",
    "    print(f\"Loading dataset for section: {section}\")\n",
    "    dataset[section] = load_dataset(\"facebook/imppres\", section)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e59927ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'presupposition_all_n_presupposition': DatasetDict({\n",
       "     all_n_presupposition: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_both_presupposition': DatasetDict({\n",
       "     both_presupposition: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_change_of_state': DatasetDict({\n",
       "     change_of_state: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_cleft_existence': DatasetDict({\n",
       "     cleft_existence: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_cleft_uniqueness': DatasetDict({\n",
       "     cleft_uniqueness: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_only_presupposition': DatasetDict({\n",
       "     only_presupposition: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_possessed_definites_existence': DatasetDict({\n",
       "     possessed_definites_existence: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_possessed_definites_uniqueness': DatasetDict({\n",
       "     possessed_definites_uniqueness: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_question_presupposition': DatasetDict({\n",
       "     question_presupposition: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " })}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8262068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the ImpPres dataset\n",
    "from tqdm import tqdm\n",
    "def evaluate_on_dataset(dataset):\n",
    "    results = []\n",
    "    label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "    for example in tqdm(dataset):\n",
    "        premise = example['premise']\n",
    "        hypothesis = example['hypothesis']\n",
    "        prediction = evaluate(premise, hypothesis)\n",
    "        results.append({\n",
    "            'premise': premise,\n",
    "            'hypothesis': hypothesis,\n",
    "            'prediction': prediction,\n",
    "            'pred_label': get_prediction(prediction),\n",
    "            'gold_label': label_names[example['gold_label']],\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8e1258",
   "metadata": {},
   "source": [
    "## Evaluate Metrics\n",
    "\n",
    "Let's use the huggingface `evaluate` package to compute the performance of the baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e2e9027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "accuracy = load(\"accuracy\")\n",
    "precision = load(\"precision\")\n",
    "recall = load(\"recall\")\n",
    "f1 = load(\"f1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ab24e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d04f0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6666666666666666,\n",
       " 'f1': 0.6666666666666666,\n",
       " 'precision': 1.0,\n",
       " 'recall': 0.5}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_metrics.compute(predictions=[0, 1, 0], references=[0, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0909d58b",
   "metadata": {},
   "source": [
    "## Your Turn\n",
    "\n",
    "Compute the classification metrics on the baseline model on each section of the ImpPres dataset.\n",
    "\n",
    "https://www.kaggle.com/code/faijanahamadkhan/llm-evaluation-framework-hugging-face provides good documentation on how to use the Huggingface evaluate library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "949c57fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on section: presupposition_all_n_presupposition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1900/1900 [09:04<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on section: presupposition_both_presupposition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1900/1900 [10:58<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on section: presupposition_change_of_state\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1900/1900 [10:21<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on section: presupposition_cleft_existence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1900/1900 [10:35<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on section: presupposition_cleft_uniqueness\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1900/1900 [10:28<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on section: presupposition_only_presupposition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1900/1900 [08:50<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on section: presupposition_possessed_definites_existence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1900/1900 [08:47<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on section: presupposition_possessed_definites_uniqueness\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1900/1900 [33:59<00:00,  1.07s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on section: presupposition_question_presupposition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1900/1900 [08:29<00:00,  3.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_547ce th {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_547ce_row0_col0, #T_547ce_row0_col1, #T_547ce_row0_col2, #T_547ce_row0_col3, #T_547ce_row0_col4, #T_547ce_row1_col0, #T_547ce_row1_col1, #T_547ce_row1_col2, #T_547ce_row1_col3, #T_547ce_row1_col4, #T_547ce_row2_col0, #T_547ce_row2_col1, #T_547ce_row2_col2, #T_547ce_row2_col3, #T_547ce_row2_col4, #T_547ce_row3_col0, #T_547ce_row3_col1, #T_547ce_row3_col2, #T_547ce_row3_col3, #T_547ce_row3_col4, #T_547ce_row4_col0, #T_547ce_row4_col1, #T_547ce_row4_col2, #T_547ce_row4_col3, #T_547ce_row4_col4, #T_547ce_row5_col0, #T_547ce_row5_col1, #T_547ce_row5_col2, #T_547ce_row5_col3, #T_547ce_row5_col4, #T_547ce_row6_col0, #T_547ce_row6_col1, #T_547ce_row6_col2, #T_547ce_row6_col3, #T_547ce_row6_col4, #T_547ce_row7_col0, #T_547ce_row7_col1, #T_547ce_row7_col2, #T_547ce_row7_col3, #T_547ce_row7_col4, #T_547ce_row8_col0, #T_547ce_row8_col1, #T_547ce_row8_col2, #T_547ce_row8_col3, #T_547ce_row8_col4, #T_547ce_row9_col0, #T_547ce_row9_col1, #T_547ce_row9_col2, #T_547ce_row9_col3, #T_547ce_row9_col4 {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_547ce\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_547ce_level0_col0\" class=\"col_heading level0 col0\" >Section</th>\n",
       "      <th id=\"T_547ce_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_547ce_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
       "      <th id=\"T_547ce_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_547ce_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_547ce_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_547ce_row0_col0\" class=\"data row0 col0\" >all_n_presupposition</td>\n",
       "      <td id=\"T_547ce_row0_col1\" class=\"data row0 col1\" >0.54</td>\n",
       "      <td id=\"T_547ce_row0_col2\" class=\"data row0 col2\" >0.52</td>\n",
       "      <td id=\"T_547ce_row0_col3\" class=\"data row0 col3\" >0.53</td>\n",
       "      <td id=\"T_547ce_row0_col4\" class=\"data row0 col4\" >0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_547ce_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_547ce_row1_col0\" class=\"data row1 col0\" >both_presupposition</td>\n",
       "      <td id=\"T_547ce_row1_col1\" class=\"data row1 col1\" >0.36</td>\n",
       "      <td id=\"T_547ce_row1_col2\" class=\"data row1 col2\" >0.29</td>\n",
       "      <td id=\"T_547ce_row1_col3\" class=\"data row1 col3\" >0.33</td>\n",
       "      <td id=\"T_547ce_row1_col4\" class=\"data row1 col4\" >0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_547ce_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_547ce_row2_col0\" class=\"data row2 col0\" >change_of_state</td>\n",
       "      <td id=\"T_547ce_row2_col1\" class=\"data row2 col1\" >0.41</td>\n",
       "      <td id=\"T_547ce_row2_col2\" class=\"data row2 col2\" >0.42</td>\n",
       "      <td id=\"T_547ce_row2_col3\" class=\"data row2 col3\" >0.41</td>\n",
       "      <td id=\"T_547ce_row2_col4\" class=\"data row2 col4\" >0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_547ce_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_547ce_row3_col0\" class=\"data row3 col0\" >cleft_existence</td>\n",
       "      <td id=\"T_547ce_row3_col1\" class=\"data row3 col1\" >0.69</td>\n",
       "      <td id=\"T_547ce_row3_col2\" class=\"data row3 col2\" >0.72</td>\n",
       "      <td id=\"T_547ce_row3_col3\" class=\"data row3 col3\" >0.73</td>\n",
       "      <td id=\"T_547ce_row3_col4\" class=\"data row3 col4\" >0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_547ce_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_547ce_row4_col0\" class=\"data row4 col0\" >cleft_uniqueness</td>\n",
       "      <td id=\"T_547ce_row4_col1\" class=\"data row4 col1\" >0.22</td>\n",
       "      <td id=\"T_547ce_row4_col2\" class=\"data row4 col2\" >0.21</td>\n",
       "      <td id=\"T_547ce_row4_col3\" class=\"data row4 col3\" >0.21</td>\n",
       "      <td id=\"T_547ce_row4_col4\" class=\"data row4 col4\" >0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_547ce_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_547ce_row5_col0\" class=\"data row5 col0\" >only_presupposition</td>\n",
       "      <td id=\"T_547ce_row5_col1\" class=\"data row5 col1\" >0.68</td>\n",
       "      <td id=\"T_547ce_row5_col2\" class=\"data row5 col2\" >0.70</td>\n",
       "      <td id=\"T_547ce_row5_col3\" class=\"data row5 col3\" >0.71</td>\n",
       "      <td id=\"T_547ce_row5_col4\" class=\"data row5 col4\" >0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_547ce_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_547ce_row6_col0\" class=\"data row6 col0\" >possessed_definites_existence</td>\n",
       "      <td id=\"T_547ce_row6_col1\" class=\"data row6 col1\" >0.77</td>\n",
       "      <td id=\"T_547ce_row6_col2\" class=\"data row6 col2\" >0.83</td>\n",
       "      <td id=\"T_547ce_row6_col3\" class=\"data row6 col3\" >0.81</td>\n",
       "      <td id=\"T_547ce_row6_col4\" class=\"data row6 col4\" >0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_547ce_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_547ce_row7_col0\" class=\"data row7 col0\" >possessed_definites_uniqueness</td>\n",
       "      <td id=\"T_547ce_row7_col1\" class=\"data row7 col1\" >0.40</td>\n",
       "      <td id=\"T_547ce_row7_col2\" class=\"data row7 col2\" >0.28</td>\n",
       "      <td id=\"T_547ce_row7_col3\" class=\"data row7 col3\" >0.36</td>\n",
       "      <td id=\"T_547ce_row7_col4\" class=\"data row7 col4\" >0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_547ce_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_547ce_row8_col0\" class=\"data row8 col0\" >question_presupposition</td>\n",
       "      <td id=\"T_547ce_row8_col1\" class=\"data row8 col1\" >0.72</td>\n",
       "      <td id=\"T_547ce_row8_col2\" class=\"data row8 col2\" >0.77</td>\n",
       "      <td id=\"T_547ce_row8_col3\" class=\"data row8 col3\" >0.77</td>\n",
       "      <td id=\"T_547ce_row8_col4\" class=\"data row8 col4\" >0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_547ce_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_547ce_row9_col0\" class=\"data row9 col0\" >Overall</td>\n",
       "      <td id=\"T_547ce_row9_col1\" class=\"data row9 col1\" >0.53</td>\n",
       "      <td id=\"T_547ce_row9_col2\" class=\"data row9 col2\" >0.53</td>\n",
       "      <td id=\"T_547ce_row9_col3\" class=\"data row9 col3\" >0.54</td>\n",
       "      <td id=\"T_547ce_row9_col4\" class=\"data row9 col4\" >0.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x214056ffc20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "results_table = []\n",
    "\n",
    "for section in sections:\n",
    "    print(f\"Working on section: {section}\")\n",
    "    sec = section[15:]\n",
    "\n",
    "    data = dataset[section]\n",
    "    data = data[sec]\n",
    "    \n",
    "    section_results = evaluate_on_dataset(data)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    predictions = [result['pred_label'] for result in section_results]\n",
    "    references = [result['gold_label'] for result in section_results]\n",
    "\n",
    "    label_to_int = {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2}\n",
    "    predictions_int = [label_to_int[pred] for pred in predictions]\n",
    "    references_int = [label_to_int[ref] for ref in references]\n",
    "\n",
    "    accuracy_score = accuracy.compute(predictions=predictions_int, references=references_int)['accuracy']\n",
    "    f1_score = f1.compute(predictions=predictions_int, references=references_int, average='macro')['f1']\n",
    "    precision_score = precision.compute(predictions=predictions_int, references=references_int, average='macro', zero_division=0)['precision']\n",
    "    recall_score = recall.compute(predictions=predictions_int, references=references_int, average='macro', zero_division=0)['recall']\n",
    "    \n",
    "    accuracies.append(accuracy_score)\n",
    "    precisions.append(precision_score)\n",
    "    recalls.append(recall_score)\n",
    "    f1s.append(f1_score)\n",
    "\n",
    "    # Append results to the table\n",
    "    results_table.append({\n",
    "        'Section': sec,\n",
    "        'Accuracy': f\"{accuracy_score:.2f}\",\n",
    "        'Precision': f\"{precision_score:.2f}\",\n",
    "        'Recall': f\"{recall_score:.2f}\",\n",
    "        'F1': f\"{f1_score:.2f}\",\n",
    "    })\n",
    "\n",
    "# Calculate overall metrics\n",
    "accuracy_all = sum(accuracies) / len(accuracies)\n",
    "precision_all = sum(precisions) / len(precisions)\n",
    "recall_all = sum(recalls) / len(recalls)\n",
    "f1_all = sum(f1s) / len(f1s)\n",
    "\n",
    "results_table.append({\n",
    "    'Section': 'Overall',\n",
    "    'Accuracy': f\"{accuracy_all:.2f}\",\n",
    "    'Precision': f\"{precision_all:.2f}\",\n",
    "    'Recall': f\"{recall_all:.2f}\",\n",
    "    'F1': f\"{f1_all:.2f}\",\n",
    "})\n",
    "\n",
    "# Display results as a table\n",
    "results_df = pd.DataFrame(results_table)\n",
    "styled_df = results_df.style.set_properties(**{'text-align': 'center'})\n",
    "styled_df = styled_df.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\n",
    "display(styled_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
