{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39a41b9a",
   "metadata": {},
   "source": [
    "# Entity Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11f3c17",
   "metadata": {},
   "source": [
    "This tutorial demonstrates how to perform entity extraction using the CoNLL-2003 dataset with DSPy. The focus is on extracting entities referring to people. We will:\n",
    "\n",
    "* Extract and label entities from the CoNLL-2003 dataset that refer to people\n",
    "* Define a DSPy program for extracting entities that refer to people\n",
    "* Optimize and evaluate the program on a subset of the CoNLL-2003 dataset\n",
    "\n",
    "By the end of this tutorial, you'll understand how to structure tasks in DSPy using signatures and modules, evaluate your system's performance, and improve its quality with optimizers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f55f25",
   "metadata": {},
   "source": [
    "## Load and Prepare the Dataset\n",
    "\n",
    "In this section, we prepare the CoNLL-2003 dataset, which is commonly used for entity extraction tasks. The dataset includes tokens annotated with entity labels such as persons, organizations, and locations.\n",
    "\n",
    "We will:\n",
    "\n",
    "1. Load the dataset using the Hugging Face datasets library.\n",
    "2. Define a function to extract tokens referring to people.\n",
    "3. Slice the dataset to create smaller subsets for training and testing.\n",
    "\n",
    "DSPy expects examples in a structured format, so we'll also transform the dataset into DSPy Examples for easy integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "914e7828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from datasets import load_dataset\n",
    "from typing import Dict, Any, List\n",
    "import dspy\n",
    "\n",
    "def load_conll_dataset() -> dict:\n",
    "    \"\"\"\n",
    "    Loads the CoNLL-2003 dataset into train, validation, and test splits.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dataset splits with keys 'train', 'validation', and 'test'.\n",
    "    \"\"\"\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        # Use a temporary Hugging Face cache directory for compatibility with certain hosted notebook\n",
    "        # environments that don't support the default Hugging Face cache directory\n",
    "        os.environ[\"HF_DATASETS_CACHE\"] = temp_dir\n",
    "        return load_dataset(\"conll2003\", trust_remote_code=True)\n",
    "\n",
    "def extract_people_entities(data_row: Dict[str, Any]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extracts entities referring to people from a row of the CoNLL-2003 dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_row (Dict[str, Any]): A row from the dataset containing tokens and NER tags.\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: List of tokens tagged as people.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        token\n",
    "        for token, ner_tag in zip(data_row[\"tokens\"], data_row[\"ner_tags\"])\n",
    "        if ner_tag in (1, 2)  # CoNLL entity codes 1 and 2 refer to people\n",
    "    ]\n",
    "\n",
    "def prepare_dataset(data_split, start: int, end: int) -> List[dspy.Example]:\n",
    "    \"\"\"\n",
    "    Prepares a sliced dataset split for use with DSPy.\n",
    "    \n",
    "    Args:\n",
    "        data_split: The dataset split (e.g., train or test).\n",
    "        start (int): Starting index of the slice.\n",
    "        end (int): Ending index of the slice.\n",
    "    \n",
    "    Returns:\n",
    "        List[dspy.Example]: List of DSPy Examples with tokens and expected labels.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        dspy.Example(\n",
    "            tokens=row[\"tokens\"],\n",
    "            expected_extracted_people=extract_people_entities(row)\n",
    "        ).with_inputs(\"tokens\")\n",
    "        for row in data_split.select(range(start, end))\n",
    "    ]\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_conll_dataset()\n",
    "\n",
    "# Prepare the training and test sets\n",
    "train_set = prepare_dataset(dataset[\"train\"], 0, 50)\n",
    "test_set = prepare_dataset(dataset[\"test\"], 0, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa801018",
   "metadata": {},
   "source": [
    "## Configure DSPy and create an Entity Extraction Program\n",
    "\n",
    "Here, we define a DSPy program for extracting entities referring to people from tokenized text.\n",
    "\n",
    "Then, we configure DSPy to use a particular language model (gpt-4o-mini) for all invocations of the program.\n",
    "\n",
    "Key DSPy Concepts Introduced:\n",
    "\n",
    "* Signatures: Define structured input/output schemas for your program.\n",
    "* Modules: Encapsulate program logic in reusable, composable units.\n",
    "\n",
    "Specifically, we'll:\n",
    "\n",
    "* Create a `PeopleExtraction` DSPy Signature to specify the input (`tokens`) and output (`extracted_people`) fields.\n",
    "* Define a `people_extractor` program that uses DSPy's built-in `dspy.ChainOfThought` module to implement the `PeopleExtraction` signature. The program extracts entities referring to people from a list of input tokens using language model (LM) prompting.\n",
    "* Use the `dspy.LM` class and `dspy.settings.configure()` method to configure the language model that DSPy will use when invoking the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17602ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class PeopleExtraction(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Extract contiguous tokens referring to specific people, if any, from a list of string tokens.\n",
    "    Output a list of tokens. In other words, do not combine multiple tokens into a single value.\n",
    "    \"\"\"\n",
    "    tokens: list[str] = dspy.InputField(desc=\"tokenized text\")\n",
    "    extracted_people: list[str] = dspy.OutputField(desc=\"all tokens referring to specific people extracted from the tokenized text\")\n",
    "\n",
    "people_extractor = dspy.ChainOfThought(PeopleExtraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb1cffec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the DSPy environment with the language model - for grok the parameters must be:\n",
    "# env variable should be in os.environ['XAI_API_KEY']\n",
    "# \"xai/grok-3-mini\"\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"grok_key.ini\") \n",
    "lm = dspy.LM('xai/grok-3-mini', api_key=os.environ['XAI_API_KEY'])\n",
    "# for ollama \n",
    "# lm = dspy.LM('ollama_chat/devstral', api_base='http://localhost:11434', api_key='')\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87644d81",
   "metadata": {},
   "source": [
    "## Define Metric and Evaluation Functions\n",
    "\n",
    "In DSPy, evaluating a program's performance is critical for iterative development. A good evaluation framework allows us to:\n",
    "\n",
    "* Measure the quality of our program's outputs.\n",
    "* Compare outputs against ground-truth labels.\n",
    "* Identify areas for improvement.\n",
    "\n",
    "What We'll Do:\n",
    "\n",
    "* Define a custom metric (`extraction_correctness_metric`) to evaluate whether the extracted entities match the ground truth.\n",
    "* Create an evaluation function (`evaluate_correctness`) to apply this metric to a training or test dataset and compute the overall accuracy.\n",
    "\n",
    "The evaluation function uses DSPy's Evaluate utility to handle parallelism and visualization of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7a3a1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction_correctness_metric(example: dspy.Example, prediction: dspy.Prediction, trace=None) -> bool:\n",
    "    \"\"\"\n",
    "    Computes correctness of entity extraction predictions.\n",
    "    \n",
    "    Args:\n",
    "        example (dspy.Example): The dataset example containing expected people entities.\n",
    "        prediction (dspy.Prediction): The prediction from the DSPy people extraction program.\n",
    "        trace: Optional trace object for debugging.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if predictions match expectations, False otherwise.\n",
    "    \"\"\"\n",
    "    return prediction.extracted_people == example.expected_extracted_people\n",
    "\n",
    "evaluate_correctness = dspy.Evaluate(\n",
    "    devset=test_set,\n",
    "    metric=extraction_correctness_metric,\n",
    "    num_threads=24,\n",
    "    display_progress=True,\n",
    "    display_table=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b5e2de",
   "metadata": {},
   "source": [
    "## Evaluate Initial Extractor\n",
    "\n",
    "Before optimizing our program, we need a baseline evaluation to understand its current performance. This helps us:\n",
    "\n",
    "* Establish a reference point for comparison after optimization.\n",
    "* Identify potential weaknesses in the initial implementation.\n",
    "\n",
    "In this step, we'll run our `people_extractor` program on the test set and measure its accuracy using the evaluation framework defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abd4d4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 190.00 / 200 (95.0%): 100%|██████████| 200/200 [01:01<00:00,  3.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 17:27:03 INFO dspy.evaluate.evaluate: Average Metric: 190 / 200 (95.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>expected_extracted_people</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>extracted_people</th>\n",
       "      <th>extraction_correctness_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[SOCCER, -, JAPAN, GET, LUCKY, WIN, ,, CHINA, IN, SURPRISE, DEFEAT...</td>\n",
       "      <td>[CHINA]</td>\n",
       "      <td>After analyzing the provided tokens: [\"SOCCER\", \"-\", \"JAPAN\", \"GET...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Nadim, Ladki]</td>\n",
       "      <td>[Nadim, Ladki]</td>\n",
       "      <td>The provided tokens are [\"Nadim\", \"Ladki\"]. Both tokens are capita...</td>\n",
       "      <td>[Nadim, Ladki]</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[AL-AIN, ,, United, Arab, Emirates, 1996-12-06]</td>\n",
       "      <td>[]</td>\n",
       "      <td>After reviewing the tokens [\"AL-AIN\", \",\", \"United\", \"Arab\", \"Emir...</td>\n",
       "      <td>[]</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Japan, began, the, defence, of, their, Asian, Cup, title, with, a...</td>\n",
       "      <td>[]</td>\n",
       "      <td>I analyzed the provided tokens to identify any that refer to speci...</td>\n",
       "      <td>[]</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[But, China, saw, their, luck, desert, them, in, the, second, matc...</td>\n",
       "      <td>[]</td>\n",
       "      <td>After reviewing the provided tokens, I analyzed each one to identi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>['The', 'Wallabies', 'have', 'their', 'sights', 'set', 'on', 'a', ...</td>\n",
       "      <td>[David, Campese]</td>\n",
       "      <td>I reviewed the list of tokens to identify any that refer to specif...</td>\n",
       "      <td>[David, Campese]</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>['The', 'Wallabies', 'currently', 'have', 'no', 'plans', 'to', 'ma...</td>\n",
       "      <td>[]</td>\n",
       "      <td>In the provided tokenized text, the phrase \"the 34-year-old winger...</td>\n",
       "      <td>[34-year-old, winger]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>['Campese', 'will', 'be', 'up', 'against', 'a', 'familiar', 'foe',...</td>\n",
       "      <td>[Campese, Rob, Andrew]</td>\n",
       "      <td>I scanned the list of tokens for contiguous tokens that refer to s...</td>\n",
       "      <td>[Campese, Rob, Andrew]</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>['\"', 'Campo', 'has', 'a', 'massive', 'following', 'in', 'this', '...</td>\n",
       "      <td>[Campo, Andrew]</td>\n",
       "      <td>I analyzed the provided tokens to identify any that refer to speci...</td>\n",
       "      <td>[Campo, Andrew]</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>['On', 'tour', ',', 'Australia', 'have', 'won', 'all', 'four', 'te...</td>\n",
       "      <td>[]</td>\n",
       "      <td>After analyzing the provided tokens, I found no tokens that refer ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    tokens  \\\n",
       "0    [SOCCER, -, JAPAN, GET, LUCKY, WIN, ,, CHINA, IN, SURPRISE, DEFEAT...   \n",
       "1                                                           [Nadim, Ladki]   \n",
       "2                          [AL-AIN, ,, United, Arab, Emirates, 1996-12-06]   \n",
       "3    [Japan, began, the, defence, of, their, Asian, Cup, title, with, a...   \n",
       "4    [But, China, saw, their, luck, desert, them, in, the, second, matc...   \n",
       "..                                                                     ...   \n",
       "195  ['The', 'Wallabies', 'have', 'their', 'sights', 'set', 'on', 'a', ...   \n",
       "196  ['The', 'Wallabies', 'currently', 'have', 'no', 'plans', 'to', 'ma...   \n",
       "197  ['Campese', 'will', 'be', 'up', 'against', 'a', 'familiar', 'foe',...   \n",
       "198  ['\"', 'Campo', 'has', 'a', 'massive', 'following', 'in', 'this', '...   \n",
       "199  ['On', 'tour', ',', 'Australia', 'have', 'won', 'all', 'four', 'te...   \n",
       "\n",
       "    expected_extracted_people  \\\n",
       "0                     [CHINA]   \n",
       "1              [Nadim, Ladki]   \n",
       "2                          []   \n",
       "3                          []   \n",
       "4                          []   \n",
       "..                        ...   \n",
       "195          [David, Campese]   \n",
       "196                        []   \n",
       "197    [Campese, Rob, Andrew]   \n",
       "198           [Campo, Andrew]   \n",
       "199                        []   \n",
       "\n",
       "                                                                 reasoning  \\\n",
       "0    After analyzing the provided tokens: [\"SOCCER\", \"-\", \"JAPAN\", \"GET...   \n",
       "1    The provided tokens are [\"Nadim\", \"Ladki\"]. Both tokens are capita...   \n",
       "2    After reviewing the tokens [\"AL-AIN\", \",\", \"United\", \"Arab\", \"Emir...   \n",
       "3    I analyzed the provided tokens to identify any that refer to speci...   \n",
       "4    After reviewing the provided tokens, I analyzed each one to identi...   \n",
       "..                                                                     ...   \n",
       "195  I reviewed the list of tokens to identify any that refer to specif...   \n",
       "196  In the provided tokenized text, the phrase \"the 34-year-old winger...   \n",
       "197  I scanned the list of tokens for contiguous tokens that refer to s...   \n",
       "198  I analyzed the provided tokens to identify any that refer to speci...   \n",
       "199  After analyzing the provided tokens, I found no tokens that refer ...   \n",
       "\n",
       "           extracted_people extraction_correctness_metric  \n",
       "0                        []                                \n",
       "1            [Nadim, Ladki]                     ✔️ [True]  \n",
       "2                        []                     ✔️ [True]  \n",
       "3                        []                     ✔️ [True]  \n",
       "4                        []                     ✔️ [True]  \n",
       "..                      ...                           ...  \n",
       "195        [David, Campese]                     ✔️ [True]  \n",
       "196   [34-year-old, winger]                                \n",
       "197  [Campese, Rob, Andrew]                     ✔️ [True]  \n",
       "198         [Campo, Andrew]                     ✔️ [True]  \n",
       "199                      []                     ✔️ [True]  \n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "95.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_correctness(people_extractor, devset=test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526b4c00",
   "metadata": {},
   "source": [
    "## Optimize the Model\n",
    "\n",
    "DSPy includes powerful optimizers that can improve the quality of your system.\n",
    "\n",
    "Here, we use DSPy's MIPROv2 optimizer to:\n",
    "\n",
    "* Automatically tune the program's language model (LM) prompt by \n",
    "    1. using the LM to adjust the prompt's instructions and \n",
    "    2. building few-shot examples from the training dataset that are augmented with reasoning generated from dspy.ChainOfThought.\n",
    "* Maximize correctness on the training set.\n",
    "\n",
    "This optimization process is automated, saving time and effort while improving accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0e892da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 17:27:03 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "RUNNING WITH THE FOLLOWING MEDIUM AUTO RUN SETTINGS:\n",
      "num_trials: 18\n",
      "minibatch: False\n",
      "num_fewshot_candidates: 12\n",
      "num_instruct_candidates: 6\n",
      "valset size: 40\n",
      "\n",
      "2025/06/24 17:27:03 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "2025/06/24 17:27:03 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
      "\n",
      "2025/06/24 17:27:03 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=12 sets of demonstrations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping set 1/12\n",
      "Bootstrapping set 2/12\n",
      "Bootstrapping set 3/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:20<00:30,  5.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Bootstrapping set 4/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:12<00:18,  3.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Bootstrapping set 5/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:13<00:30,  4.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Bootstrapping set 6/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Bootstrapping set 7/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:00<00:00, 332.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 8/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:00<00:00, 125.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Bootstrapping set 9/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:00<00:00, 363.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Bootstrapping set 10/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:00<00:00, 154.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 11/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 3/10 [00:06<00:14,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Bootstrapping set 12/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:00<00:00, 398.55it/s]\n",
      "2025/06/24 17:27:57 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "2025/06/24 17:27:57 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Error getting source code: unhashable type: 'dict'.\n",
      "\n",
      "Running without program aware proposer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 17:28:06 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "Proposing N=6 instructions...\n",
      "\n",
      "2025/06/24 17:28:52 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
      "\n",
      "2025/06/24 17:28:52 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Extract contiguous tokens referring to specific people, if any, from a list of string tokens.\n",
      "Output a list of tokens. In other words, do not combine multiple tokens into a single value.\n",
      "\n",
      "2025/06/24 17:28:52 INFO dspy.teleprompt.mipro_optimizer_v2: 1: You are tasked with performing named entity recognition specifically for extracting contiguous tokens that refer to individual people's names from a list of string tokens derived from news articles and official reports on topics such as EU politics, public health issues like mad cow disease, and international trade involving countries like Germany, Britain, and France. Your goal is to identify and output a list of these tokens without combining or merging them into a single value. For example, if the tokens include a sequence like ['Peter', 'Blackburn'] that appears to be a person's full name, extract them as separate elements in the list. However, if tokens like ['EU', 'rejects', 'German'] do not refer to specific individuals, exclude them entirely. Always reason step by step: review each token in the list, determine if it is a proper noun indicating a person (such as first or last names), ensure the tokens are contiguous, and only include those that clearly represent human entities while ignoring organizations, places, dates, or other non-person references. The output should be a clean list of strings, e.g., ['Peter', 'Blackburn'], or an empty list [] if no such tokens are found.\n",
      "\n",
      "2025/06/24 17:28:52 INFO dspy.teleprompt.mipro_optimizer_v2: 2: Given a list of string tokens from news articles or reports related to EU politics, public health, or international trade, your task is to identify and extract only those contiguous tokens that refer to specific individuals (such as proper names of people, e.g., 'Peter' or 'Blackburn'). Focus on tokens that are proper nouns indicating personal names, while ignoring organizations, places, dates, or other non-person entities. Think step by step: First, review the entire list of tokens; second, analyze each token or group of contiguous tokens to determine if they represent a person's name; third, compile a list of the exact tokens that qualify, without merging or altering them. Finally, output the list of extracted tokens in a simple array format, or an empty list if no such tokens are found.\n",
      "\n",
      "2025/06/24 17:28:52 INFO dspy.teleprompt.mipro_optimizer_v2: 3: Given a list of tokenized strings derived from news articles and official reports focused on EU politics, public health issues like mad cow disease, and international trade involving countries such as Germany, Britain, and France, your task is to extract any contiguous tokens that specifically refer to individual people, such as proper nouns for persons (e.g., 'Werner Zwingmann' or 'Fischler'). To accomplish this, analyze the provided list of tokens step by step: Review each token or sequence of tokens in context to determine if it unambiguously represents a specific person's name, ensuring you only include those that are relevant for named entity recognition. Output the result as a simple list of strings, where each element is an exact token from the input list without any modifications, combinations, or merging of tokens into a single value. For instance, if a person's name spans multiple tokens, extract each token separately as per the original list, but only if they qualify as referring to a specific person. Focus on maintaining precision and objectivity, as this is for applications like journalism and regulatory analysis.\n",
      "\n",
      "2025/06/24 17:28:52 INFO dspy.teleprompt.mipro_optimizer_v2: 4: In this high-stakes investigative scenario, where inaccurate extraction of person names from EU political documents could lead to misinformation, public health crises like mad cow disease outbreaks, or diplomatic incidents involving countries like Germany and Britain, you must carefully extract contiguous tokens that refer to specific people from a provided list of string tokens. Think step by step: analyze each token to determine if it is a proper noun referring to an individual, consider the context from news articles and official reports, and ensure you only output a list of the individual tokens (e.g., ['Nikolaus', 'van', 'der', 'Pas']) without combining them into a single value. Your precision is critical to support regulatory analysis and prevent real-world consequences.\n",
      "\n",
      "2025/06/24 17:28:52 INFO dspy.teleprompt.mipro_optimizer_v2: 5: You are an expert in named entity recognition, specializing in extracting person names from news articles, official reports, and texts related to EU politics, public health, and international trade. Your task is to analyze a list of string tokens and extract any contiguous tokens that refer to specific people, such as proper nouns for individuals. Think step by step: Review each token or sequence of tokens to identify if they denote a specific person, ensuring you only include relevant entities. Output a list of the extracted tokens as they appear, without combining multiple tokens into a single value. If no such tokens are found, output an empty list.\n",
      "\n",
      "2025/06/24 17:28:52 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/06/24 17:28:52 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "2025/06/24 17:28:52 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
      "\n",
      "2025/06/24 17:28:52 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 18 - Full Evaluation of Default Program ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 39.00 / 40 (97.5%): 100%|██████████| 40/40 [00:32<00:00,  1.23it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 17:29:25 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
      "2025/06/24 17:29:25 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 97.5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hadar\\anaconda3\\Lib\\site-packages\\optuna\\_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "2025/06/24 17:29:25 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 2 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 39.00 / 40 (97.5%): 100%|██████████| 40/40 [00:33<00:00,  1.18it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 17:29:59 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
      "2025/06/24 17:29:59 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 6'].\n",
      "2025/06/24 17:29:59 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [97.5, 97.5]\n",
      "2025/06/24 17:29:59 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/06/24 17:29:59 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/24 17:29:59 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 3 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 38.00 / 40 (95.0%): 100%|██████████| 40/40 [00:34<00:00,  1.17it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 17:30:33 INFO dspy.evaluate.evaluate: Average Metric: 38 / 40 (95.0%)\n",
      "2025/06/24 17:30:33 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 95.0 with parameters ['Predictor 0: Instruction 4', 'Predictor 0: Few-Shot Set 2'].\n",
      "2025/06/24 17:30:33 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [97.5, 97.5, 95.0]\n",
      "2025/06/24 17:30:33 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/06/24 17:30:33 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/24 17:30:33 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 4 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 38.00 / 40 (95.0%): 100%|██████████| 40/40 [00:29<00:00,  1.34it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 17:31:03 INFO dspy.evaluate.evaluate: Average Metric: 38 / 40 (95.0%)\n",
      "2025/06/24 17:31:04 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 95.0 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 6'].\n",
      "2025/06/24 17:31:04 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [97.5, 97.5, 95.0, 95.0]\n",
      "2025/06/24 17:31:04 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/06/24 17:31:04 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/24 17:31:04 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 5 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.00 / 40 (97.5%): 100%|██████████| 40/40 [00:27<00:00,  1.44it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 17:31:31 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
      "2025/06/24 17:31:31 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 4'].\n",
      "2025/06/24 17:31:31 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [97.5, 97.5, 95.0, 95.0, 97.5]\n",
      "2025/06/24 17:31:31 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/06/24 17:31:31 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/24 17:31:31 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 6 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.00 / 40 (97.5%): 100%|██████████| 40/40 [00:30<00:00,  1.30it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 17:32:02 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
      "2025/06/24 17:32:02 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 3', 'Predictor 0: Few-Shot Set 5'].\n",
      "2025/06/24 17:32:02 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [97.5, 97.5, 95.0, 95.0, 97.5, 97.5]\n",
      "2025/06/24 17:32:02 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/06/24 17:32:02 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/24 17:32:02 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 7 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 38.00 / 40 (95.0%): 100%|██████████| 40/40 [00:33<00:00,  1.20it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 17:32:36 INFO dspy.evaluate.evaluate: Average Metric: 38 / 40 (95.0%)\n",
      "2025/06/24 17:32:36 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 95.0 with parameters ['Predictor 0: Instruction 4', 'Predictor 0: Few-Shot Set 6'].\n",
      "2025/06/24 17:32:36 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [97.5, 97.5, 95.0, 95.0, 97.5, 97.5, 95.0]\n",
      "2025/06/24 17:32:36 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/06/24 17:32:36 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/24 17:32:36 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 8 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.00 / 40 (97.5%): 100%|██████████| 40/40 [00:35<00:00,  1.12it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 17:33:12 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
      "2025/06/24 17:33:12 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 1'].\n",
      "2025/06/24 17:33:12 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [97.5, 97.5, 95.0, 95.0, 97.5, 97.5, 95.0, 97.5]\n",
      "2025/06/24 17:33:12 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/06/24 17:33:12 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/24 17:33:12 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 9 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.00 / 40 (97.5%): 100%|██████████| 40/40 [00:27<00:00,  1.47it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 17:33:39 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
      "2025/06/24 17:33:39 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 3', 'Predictor 0: Few-Shot Set 3'].\n",
      "2025/06/24 17:33:39 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [97.5, 97.5, 95.0, 95.0, 97.5, 97.5, 95.0, 97.5, 97.5]\n",
      "2025/06/24 17:33:39 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/06/24 17:33:39 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/24 17:33:39 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 10 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.00 / 40 (97.5%): 100%|██████████| 40/40 [00:27<00:00,  1.44it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 17:34:07 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
      "2025/06/24 17:34:07 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 3', 'Predictor 0: Few-Shot Set 10'].\n",
      "2025/06/24 17:34:07 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [97.5, 97.5, 95.0, 95.0, 97.5, 97.5, 95.0, 97.5, 97.5, 97.5]\n",
      "2025/06/24 17:34:07 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/06/24 17:34:07 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/24 17:34:07 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 11 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.00 / 40 (97.5%): 100%|██████████| 40/40 [00:00<00:00, 459.91it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 17:34:07 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 17:34:08 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 0'].\n",
      "2025/06/24 17:34:08 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [97.5, 97.5, 95.0, 95.0, 97.5, 97.5, 95.0, 97.5, 97.5, 97.5, 97.5]\n",
      "2025/06/24 17:34:08 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/06/24 17:34:08 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/24 17:34:08 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 12 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 39.00 / 40 (97.5%): 100%|██████████| 40/40 [00:00<00:00, 669.60it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 17:34:08 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
      "2025/06/24 17:34:08 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 6'].\n",
      "2025/06/24 17:34:08 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [97.5, 97.5, 95.0, 95.0, 97.5, 97.5, 95.0, 97.5, 97.5, 97.5, 97.5, 97.5]\n",
      "2025/06/24 17:34:08 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/06/24 17:34:08 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/24 17:34:08 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 13 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.00 / 40 (97.5%): 100%|██████████| 40/40 [00:27<00:00,  1.46it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 17:34:35 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
      "2025/06/24 17:34:35 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 8'].\n",
      "2025/06/24 17:34:35 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [97.5, 97.5, 95.0, 95.0, 97.5, 97.5, 95.0, 97.5, 97.5, 97.5, 97.5, 97.5, 97.5]\n",
      "2025/06/24 17:34:35 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/06/24 17:34:35 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/24 17:34:35 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 14 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.00 / 40 (97.5%): 100%|██████████| 40/40 [00:39<00:00,  1.00it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 17:35:15 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 17:35:16 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 0'].\n",
      "2025/06/24 17:35:16 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [97.5, 97.5, 95.0, 95.0, 97.5, 97.5, 95.0, 97.5, 97.5, 97.5, 97.5, 97.5, 97.5, 97.5]\n",
      "2025/06/24 17:35:16 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/06/24 17:35:16 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/24 17:35:16 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 15 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 39.00 / 40 (97.5%): 100%|██████████| 40/40 [00:32<00:00,  1.24it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 17:35:48 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
      "2025/06/24 17:35:48 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 7'].\n",
      "2025/06/24 17:35:48 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [97.5, 97.5, 95.0, 95.0, 97.5, 97.5, 95.0, 97.5, 97.5, 97.5, 97.5, 97.5, 97.5, 97.5, 97.5]\n",
      "2025/06/24 17:35:48 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/06/24 17:35:48 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/24 17:35:48 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 16 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 38.00 / 40 (95.0%): 100%|██████████| 40/40 [00:32<00:00,  1.21it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 17:36:21 INFO dspy.evaluate.evaluate: Average Metric: 38 / 40 (95.0%)\n",
      "2025/06/24 17:36:21 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 95.0 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 9'].\n",
      "2025/06/24 17:36:21 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [97.5, 97.5, 95.0, 95.0, 97.5, 97.5, 95.0, 97.5, 97.5, 97.5, 97.5, 97.5, 97.5, 97.5, 97.5, 95.0]\n",
      "2025/06/24 17:36:21 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/06/24 17:36:21 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/24 17:36:21 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 17 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.00 / 40 (97.5%): 100%|██████████| 40/40 [00:29<00:00,  1.38it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 17:36:51 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
      "2025/06/24 17:36:51 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 11'].\n",
      "2025/06/24 17:36:51 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [97.5, 97.5, 95.0, 95.0, 97.5, 97.5, 95.0, 97.5, 97.5, 97.5, 97.5, 97.5, 97.5, 97.5, 97.5, 95.0, 97.5]\n",
      "2025/06/24 17:36:51 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/06/24 17:36:51 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/24 17:36:51 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 18 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.00 / 40 (97.5%): 100%|██████████| 40/40 [00:00<00:00, 652.89it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 17:36:51 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
      "2025/06/24 17:36:51 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 0'].\n",
      "2025/06/24 17:36:51 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [97.5, 97.5, 95.0, 95.0, 97.5, 97.5, 95.0, 97.5, 97.5, 97.5, 97.5, 97.5, 97.5, 97.5, 97.5, 95.0, 97.5, 97.5]\n",
      "2025/06/24 17:36:51 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/06/24 17:36:51 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/24 17:36:51 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 19 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.00 / 40 (97.5%): 100%|██████████| 40/40 [00:29<00:00,  1.37it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 17:37:20 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
      "2025/06/24 17:37:20 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 3'].\n",
      "2025/06/24 17:37:20 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [97.5, 97.5, 95.0, 95.0, 97.5, 97.5, 95.0, 97.5, 97.5, 97.5, 97.5, 97.5, 97.5, 97.5, 97.5, 95.0, 97.5, 97.5, 97.5]\n",
      "2025/06/24 17:37:20 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
      "2025/06/24 17:37:20 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/24 17:37:20 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 97.5!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mipro_optimizer = dspy.MIPROv2(\n",
    "    metric=extraction_correctness_metric,\n",
    "    auto=\"medium\",\n",
    ")\n",
    "optimized_people_extractor = mipro_optimizer.compile(\n",
    "    people_extractor,\n",
    "    trainset=train_set,\n",
    "    max_bootstrapped_demos=4,\n",
    "    requires_permission_to_run=False,\n",
    "    minibatch=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8903605b",
   "metadata": {},
   "source": [
    "## Evaluate Optimized Program\n",
    "\n",
    "After optimization, we re-evaluate the program on the test set to measure improvements. Comparing the optimized and initial results allows us to:\n",
    "\n",
    "* Quantify the benefits of optimization.\n",
    "* Validate that the program generalizes well to unseen data.\n",
    "\n",
    "In this case, we see that accuracy of the program on the test dataset has improved significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78e77328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 190.00 / 200 (95.0%): 100%|██████████| 200/200 [00:00<00:00, 635.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 17:37:21 INFO dspy.evaluate.evaluate: Average Metric: 190 / 200 (95.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>expected_extracted_people</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>extracted_people</th>\n",
       "      <th>extraction_correctness_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[SOCCER, -, JAPAN, GET, LUCKY, WIN, ,, CHINA, IN, SURPRISE, DEFEAT...</td>\n",
       "      <td>[CHINA]</td>\n",
       "      <td>After analyzing the provided tokens: [\"SOCCER\", \"-\", \"JAPAN\", \"GET...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Nadim, Ladki]</td>\n",
       "      <td>[Nadim, Ladki]</td>\n",
       "      <td>The provided tokens are [\"Nadim\", \"Ladki\"]. Both tokens are capita...</td>\n",
       "      <td>[Nadim, Ladki]</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[AL-AIN, ,, United, Arab, Emirates, 1996-12-06]</td>\n",
       "      <td>[]</td>\n",
       "      <td>After reviewing the tokens [\"AL-AIN\", \",\", \"United\", \"Arab\", \"Emir...</td>\n",
       "      <td>[]</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Japan, began, the, defence, of, their, Asian, Cup, title, with, a...</td>\n",
       "      <td>[]</td>\n",
       "      <td>I analyzed the provided tokens to identify any that refer to speci...</td>\n",
       "      <td>[]</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[But, China, saw, their, luck, desert, them, in, the, second, matc...</td>\n",
       "      <td>[]</td>\n",
       "      <td>After reviewing the provided tokens, I analyzed each one to identi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>['The', 'Wallabies', 'have', 'their', 'sights', 'set', 'on', 'a', ...</td>\n",
       "      <td>[David, Campese]</td>\n",
       "      <td>I reviewed the list of tokens to identify any that refer to specif...</td>\n",
       "      <td>[David, Campese]</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>['The', 'Wallabies', 'currently', 'have', 'no', 'plans', 'to', 'ma...</td>\n",
       "      <td>[]</td>\n",
       "      <td>In the provided tokenized text, the phrase \"the 34-year-old winger...</td>\n",
       "      <td>[34-year-old, winger]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>['Campese', 'will', 'be', 'up', 'against', 'a', 'familiar', 'foe',...</td>\n",
       "      <td>[Campese, Rob, Andrew]</td>\n",
       "      <td>I scanned the list of tokens for contiguous tokens that refer to s...</td>\n",
       "      <td>[Campese, Rob, Andrew]</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>['\"', 'Campo', 'has', 'a', 'massive', 'following', 'in', 'this', '...</td>\n",
       "      <td>[Campo, Andrew]</td>\n",
       "      <td>I analyzed the provided tokens to identify any that refer to speci...</td>\n",
       "      <td>[Campo, Andrew]</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>['On', 'tour', ',', 'Australia', 'have', 'won', 'all', 'four', 'te...</td>\n",
       "      <td>[]</td>\n",
       "      <td>After analyzing the provided tokens, I found no tokens that refer ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    tokens  \\\n",
       "0    [SOCCER, -, JAPAN, GET, LUCKY, WIN, ,, CHINA, IN, SURPRISE, DEFEAT...   \n",
       "1                                                           [Nadim, Ladki]   \n",
       "2                          [AL-AIN, ,, United, Arab, Emirates, 1996-12-06]   \n",
       "3    [Japan, began, the, defence, of, their, Asian, Cup, title, with, a...   \n",
       "4    [But, China, saw, their, luck, desert, them, in, the, second, matc...   \n",
       "..                                                                     ...   \n",
       "195  ['The', 'Wallabies', 'have', 'their', 'sights', 'set', 'on', 'a', ...   \n",
       "196  ['The', 'Wallabies', 'currently', 'have', 'no', 'plans', 'to', 'ma...   \n",
       "197  ['Campese', 'will', 'be', 'up', 'against', 'a', 'familiar', 'foe',...   \n",
       "198  ['\"', 'Campo', 'has', 'a', 'massive', 'following', 'in', 'this', '...   \n",
       "199  ['On', 'tour', ',', 'Australia', 'have', 'won', 'all', 'four', 'te...   \n",
       "\n",
       "    expected_extracted_people  \\\n",
       "0                     [CHINA]   \n",
       "1              [Nadim, Ladki]   \n",
       "2                          []   \n",
       "3                          []   \n",
       "4                          []   \n",
       "..                        ...   \n",
       "195          [David, Campese]   \n",
       "196                        []   \n",
       "197    [Campese, Rob, Andrew]   \n",
       "198           [Campo, Andrew]   \n",
       "199                        []   \n",
       "\n",
       "                                                                 reasoning  \\\n",
       "0    After analyzing the provided tokens: [\"SOCCER\", \"-\", \"JAPAN\", \"GET...   \n",
       "1    The provided tokens are [\"Nadim\", \"Ladki\"]. Both tokens are capita...   \n",
       "2    After reviewing the tokens [\"AL-AIN\", \",\", \"United\", \"Arab\", \"Emir...   \n",
       "3    I analyzed the provided tokens to identify any that refer to speci...   \n",
       "4    After reviewing the provided tokens, I analyzed each one to identi...   \n",
       "..                                                                     ...   \n",
       "195  I reviewed the list of tokens to identify any that refer to specif...   \n",
       "196  In the provided tokenized text, the phrase \"the 34-year-old winger...   \n",
       "197  I scanned the list of tokens for contiguous tokens that refer to s...   \n",
       "198  I analyzed the provided tokens to identify any that refer to speci...   \n",
       "199  After analyzing the provided tokens, I found no tokens that refer ...   \n",
       "\n",
       "           extracted_people extraction_correctness_metric  \n",
       "0                        []                                \n",
       "1            [Nadim, Ladki]                     ✔️ [True]  \n",
       "2                        []                     ✔️ [True]  \n",
       "3                        []                     ✔️ [True]  \n",
       "4                        []                     ✔️ [True]  \n",
       "..                      ...                           ...  \n",
       "195        [David, Campese]                     ✔️ [True]  \n",
       "196   [34-year-old, winger]                                \n",
       "197  [Campese, Rob, Andrew]                     ✔️ [True]  \n",
       "198         [Campo, Andrew]                     ✔️ [True]  \n",
       "199                      []                     ✔️ [True]  \n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "95.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_correctness(optimized_people_extractor, devset=test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59947274",
   "metadata": {},
   "source": [
    "## Inspect Optimized Program's Prompt\n",
    "\n",
    "After optimizing the program, we can inspect the history of interactions to see how DSPy has augmented the program's prompt with few-shot examples. This step demonstrates:\n",
    "\n",
    "* The structure of the prompt used by the program.\n",
    "* How few-shot examples are added to guide the model's behavior.\n",
    "\n",
    "Use `inspect_history(n=1)` to view the last interaction and analyze the generated prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b9b4af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-06-24T17:37:21.177945]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `tokens` (list[str]): tokenized text\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `extracted_people` (list[str]): all tokens referring to specific people extracted from the tokenized text\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## tokens ## ]]\n",
      "{tokens}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## extracted_people ## ]]\n",
      "{extracted_people}        # note: the value you produce must adhere to the JSON schema: {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Extract contiguous tokens referring to specific people, if any, from a list of string tokens.\n",
      "        Output a list of tokens. In other words, do not combine multiple tokens into a single value.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## tokens ## ]]\n",
      "[\"Leeds\", \"'\", \"England\", \"under-21\", \"striker\", \"Lee\", \"Bowyer\", \"was\", \"fined\", \"4,500\", \"pounds\", \"(\", \"$\", \"7,400\", \")\", \"on\", \"Friday\", \"for\", \"hurling\", \"chairs\", \"at\", \"restaurant\", \"staff\", \"during\", \"a\", \"disturbance\", \"at\", \"a\", \"McDonald\", \"'s\", \"fast-food\", \"restaurant\", \".\"]\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## extracted_people ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "In the provided list of tokens, I analyzed each token to identify those that refer to specific people. The tokens \"Lee\" and \"Bowyer\" form a contiguous sequence that appears to be a proper name, as they are described in the context of a \"striker\" for \"Leeds, England under-21,\" which suggests a reference to a real person (likely a soccer player). Other tokens, such as \"Leeds,\" \"England,\" or \"McDonald,\" refer to places, organizations, or general terms, not specific individuals. Therefore, I extracted only the tokens \"Lee\" and \"Bowyer\" as they directly refer to a person, without combining them into a single value.\n",
      "\n",
      "[[ ## extracted_people ## ]]\n",
      "[\"Lee\", \"Bowyer\"]\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4a99667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2982494"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost = sum([x['cost'] for x in lm.history if x['cost'] is not None])  # cost in USD, as calculated by LiteLLM for certain providers\n",
    "cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1238f485",
   "metadata": {},
   "source": [
    "## Saving and Loading Optimized Programs\n",
    "\n",
    "DSPy supports saving and loading programs, enabling you to reuse optimized systems without the need to re-optimize from scratch. \n",
    "This feature is especially useful for deploying your programs in production environments or sharing them with collaborators.\n",
    "\n",
    "In this step, we'll save the optimized program to a file and demonstrate how to load it back for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec565965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Marcello', 'Cuttitta']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_people_extractor.save(\"optimized_extractor.json\")\n",
    "\n",
    "loaded_people_extractor = dspy.ChainOfThought(PeopleExtraction)\n",
    "loaded_people_extractor.load(\"optimized_extractor.json\")\n",
    "\n",
    "loaded_people_extractor(tokens=[\"Italy\", \"recalled\", \"Marcello\", \"Cuttitta\"]).extracted_people"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
